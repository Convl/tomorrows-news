"""modify Event table, rename and modify EventSource table to ExtractedEvent

Revision ID: d0bcf69bb139
Revises: d61d3290004d
Create Date: 2025-07-25 09:06:04.140992

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'd0bcf69bb139'
down_revision: Union[str, Sequence[str], None] = 'd61d3290004d'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('extracted_events',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('title', sa.String(length=500), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('date', sa.DateTime(timezone=True), nullable=False),
    sa.Column('location', sa.String(length=300), nullable=True),
    sa.Column('significance', sa.Float(), nullable=False),
    sa.Column('duration', sa.String(length=100), nullable=True),
    sa.Column('additional_infos', sa.JSON(), nullable=True),
    sa.Column('source_url', sa.String(length=1000), nullable=False),
    sa.Column('source_title', sa.String(length=500), nullable=True),
    sa.Column('source_published_date', sa.DateTime(timezone=True), nullable=False),
    sa.Column('degrees_of_separation', sa.Integer(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('semantic_vector', sa.Text(), nullable=True),
    sa.Column('location_vector', sa.Text(), nullable=True),
    sa.Column('scraping_source_id', sa.Integer(), nullable=False),
    sa.Column('event_id', sa.Integer(), nullable=False),
    sa.ForeignKeyConstraint(['event_id'], ['events.id'], ),
    sa.ForeignKeyConstraint(['scraping_source_id'], ['scraping_sources.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_extracted_events_date'), 'extracted_events', ['date'], unique=False)
    op.create_index(op.f('ix_extracted_events_id'), 'extracted_events', ['id'], unique=False)
    op.create_index(op.f('ix_extracted_events_title'), 'extracted_events', ['title'], unique=False)
    op.drop_index(op.f('ix_apscheduler_jobs_next_run_time'), table_name='apscheduler_jobs')
    op.drop_table('apscheduler_jobs')
    op.drop_index(op.f('ix_event_sources_id'), table_name='event_sources')
    op.drop_index(op.f('ix_event_sources_url'), table_name='event_sources')
    op.drop_table('event_sources')
    op.add_column('events', sa.Column('date', sa.DateTime(timezone=True), nullable=False))
    op.add_column('events', sa.Column('significance', sa.Float(), nullable=False))
    op.add_column('events', sa.Column('duration', sa.String(length=100), nullable=True))
    op.add_column('events', sa.Column('additional_infos', sa.JSON(), nullable=True))
    op.add_column('events', sa.Column('title_from_id', sa.Integer(), nullable=True))
    op.add_column('events', sa.Column('description_from_id', sa.Integer(), nullable=True))
    op.add_column('events', sa.Column('date_from_id', sa.Integer(), nullable=True))
    op.add_column('events', sa.Column('location_from_id', sa.Integer(), nullable=True))
    op.add_column('events', sa.Column('duration_from_id', sa.Integer(), nullable=True))
    op.add_column('events', sa.Column('confidence_score', sa.Float(), nullable=False))
    op.add_column('events', sa.Column('semantic_vector', sa.Text(), nullable=True))
    op.add_column('events', sa.Column('location_vector', sa.Text(), nullable=True))
    op.add_column('events', sa.Column('update_history', sa.JSON(), nullable=False))
    op.drop_index(op.f('ix_events_event_date'), table_name='events')
    op.drop_index(op.f('ix_events_similarity_hash'), table_name='events')
    op.create_index(op.f('ix_events_date'), 'events', ['date'], unique=False)
    op.drop_constraint(op.f('events_duplicate_of_id_fkey'), 'events', type_='foreignkey')
    op.create_foreign_key(None, 'events', 'extracted_events', ['date_from_id'], ['id'])
    op.create_foreign_key(None, 'events', 'extracted_events', ['location_from_id'], ['id'])
    op.create_foreign_key(None, 'events', 'extracted_events', ['duration_from_id'], ['id'])
    op.create_foreign_key(None, 'events', 'extracted_events', ['description_from_id'], ['id'])
    op.create_foreign_key(None, 'events', 'extracted_events', ['title_from_id'], ['id'])
    op.drop_column('events', 'duplicate_of_id')
    op.drop_column('events', 'updated_at')
    op.drop_column('events', 'custom_fields_config')
    op.drop_column('events', 'custom_fields')
    op.drop_column('events', 'embedding_vector')
    op.drop_column('events', 'is_duplicate')
    op.drop_column('events', 'processing_notes')
    op.drop_column('events', 'event_date')
    op.drop_column('events', 'is_verified')
    op.drop_column('events', 'event_type')
    op.drop_column('events', 'similarity_hash')
    op.drop_column('events', 'source_url')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('events', sa.Column('source_url', sa.VARCHAR(length=1000), autoincrement=False, nullable=True))
    op.add_column('events', sa.Column('similarity_hash', sa.VARCHAR(length=64), autoincrement=False, nullable=True))
    op.add_column('events', sa.Column('event_type', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
    op.add_column('events', sa.Column('is_verified', sa.BOOLEAN(), autoincrement=False, nullable=False))
    op.add_column('events', sa.Column('event_date', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False))
    op.add_column('events', sa.Column('processing_notes', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('events', sa.Column('is_duplicate', sa.BOOLEAN(), autoincrement=False, nullable=False))
    op.add_column('events', sa.Column('embedding_vector', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('events', sa.Column('custom_fields', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('events', sa.Column('custom_fields_config', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('events', sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False))
    op.add_column('events', sa.Column('duplicate_of_id', sa.INTEGER(), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'events', type_='foreignkey')
    op.drop_constraint(None, 'events', type_='foreignkey')
    op.drop_constraint(None, 'events', type_='foreignkey')
    op.drop_constraint(None, 'events', type_='foreignkey')
    op.drop_constraint(None, 'events', type_='foreignkey')
    op.create_foreign_key(op.f('events_duplicate_of_id_fkey'), 'events', 'events', ['duplicate_of_id'], ['id'])
    op.drop_index(op.f('ix_events_date'), table_name='events')
    op.create_index(op.f('ix_events_similarity_hash'), 'events', ['similarity_hash'], unique=False)
    op.create_index(op.f('ix_events_event_date'), 'events', ['event_date'], unique=False)
    op.drop_column('events', 'update_history')
    op.drop_column('events', 'location_vector')
    op.drop_column('events', 'semantic_vector')
    op.drop_column('events', 'confidence_score')
    op.drop_column('events', 'duration_from_id')
    op.drop_column('events', 'location_from_id')
    op.drop_column('events', 'date_from_id')
    op.drop_column('events', 'description_from_id')
    op.drop_column('events', 'title_from_id')
    op.drop_column('events', 'additional_infos')
    op.drop_column('events', 'duration')
    op.drop_column('events', 'significance')
    op.drop_column('events', 'date')
    op.create_table('event_sources',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('url', sa.VARCHAR(length=1000), autoincrement=False, nullable=False),
    sa.Column('title', sa.VARCHAR(length=500), autoincrement=False, nullable=True),
    sa.Column('extraction_method', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('extraction_metadata', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('confidence_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('found_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('event_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['event_id'], ['events.id'], name=op.f('event_sources_event_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('event_sources_pkey'))
    )
    op.create_index(op.f('ix_event_sources_url'), 'event_sources', ['url'], unique=False)
    op.create_index(op.f('ix_event_sources_id'), 'event_sources', ['id'], unique=False)
    op.create_table('apscheduler_jobs',
    sa.Column('id', sa.VARCHAR(length=191), autoincrement=False, nullable=False),
    sa.Column('next_run_time', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('job_state', postgresql.BYTEA(), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('apscheduler_jobs_pkey'))
    )
    op.create_index(op.f('ix_apscheduler_jobs_next_run_time'), 'apscheduler_jobs', ['next_run_time'], unique=False)
    op.drop_index(op.f('ix_extracted_events_title'), table_name='extracted_events')
    op.drop_index(op.f('ix_extracted_events_id'), table_name='extracted_events')
    op.drop_index(op.f('ix_extracted_events_date'), table_name='extracted_events')
    op.drop_table('extracted_events')
    # ### end Alembic commands ###
