"""Separate scraping sources from event sources + minor other changes

Revision ID: 618ee661f747
Revises: e2c63680af1f
Create Date: 2025-07-15 11:31:08.293375

"""

from typing import Sequence, Union

import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

from alembic import op

# revision identifiers, used by Alembic.
revision: str = "618ee661f747"
down_revision: Union[str, Sequence[str], None] = "e2c63680af1f"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "event_sources",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("url", sa.String(length=1000), nullable=False),
        sa.Column("title", sa.String(length=500), nullable=True),
        sa.Column("extraction_method", sa.String(length=50), nullable=True),
        sa.Column("extraction_metadata", sa.JSON(), nullable=True),
        sa.Column("confidence_score", sa.Float(), nullable=True),
        sa.Column("found_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(op.f("ix_event_sources_id"), "event_sources", ["id"], unique=False)
    op.create_index(op.f("ix_event_sources_url"), "event_sources", ["url"], unique=False)
    op.create_table(
        "scraping_sources",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("name", sa.String(length=200), nullable=False),
        sa.Column("base_url", sa.String(length=500), nullable=False),
        sa.Column("source_type", sa.String(length=50), nullable=False),
        sa.Column("country", sa.String(length=100), nullable=True),
        sa.Column("language", sa.String(length=10), nullable=True),
        sa.Column("description", sa.Text(), nullable=True),
        sa.Column("scraping_config", sa.JSON(), nullable=True),
        sa.Column("is_active", sa.Boolean(), nullable=True),
        sa.Column("last_scraped_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column("user_id", sa.Integer(), nullable=False),
        sa.Column("created_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=True),
        sa.Column("updated_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=True),
        sa.ForeignKeyConstraint(
            ["user_id"],
            ["users.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(op.f("ix_scraping_sources_id"), "scraping_sources", ["id"], unique=False)
    op.create_index(op.f("ix_scraping_sources_name"), "scraping_sources", ["name"], unique=False)

    # First, add the new column and create new foreign key
    op.add_column("events", sa.Column("event_source_id", sa.Integer(), nullable=True))
    op.create_foreign_key(None, "events", "event_sources", ["event_source_id"], ["id"])

    # Then, drop the old foreign key constraint and column
    op.drop_constraint("events_source_id_fkey", "events", type_="foreignkey")
    op.drop_column("events", "source_id")

    # Finally, drop the old sources table
    op.drop_index(op.f("ix_sources_id"), table_name="sources")
    op.drop_index(op.f("ix_sources_name"), table_name="sources")
    op.drop_table("sources")
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column("events", sa.Column("source_id", sa.INTEGER(), autoincrement=False, nullable=True))
    op.drop_constraint("events_event_source_id_fkey", "events", type_="foreignkey")
    op.create_foreign_key(op.f("events_source_id_fkey"), "events", "sources", ["source_id"], ["id"])
    op.drop_column("events", "event_source_id")
    op.create_table(
        "sources",
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column("name", sa.VARCHAR(length=200), autoincrement=False, nullable=False),
        sa.Column("base_url", sa.VARCHAR(length=500), autoincrement=False, nullable=False),
        sa.Column("source_type", sa.VARCHAR(length=50), autoincrement=False, nullable=False),
        sa.Column("country", sa.VARCHAR(length=100), autoincrement=False, nullable=True),
        sa.Column("language", sa.VARCHAR(length=10), autoincrement=False, nullable=True),
        sa.Column("reliability_score", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column("is_active", sa.BOOLEAN(), autoincrement=False, nullable=True),
        sa.Column("scraping_config", postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
        sa.Column("last_scraped_at", postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "updated_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=True,
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("sources_pkey")),
    )
    op.create_index(op.f("ix_sources_name"), "sources", ["name"], unique=False)
    op.create_index(op.f("ix_sources_id"), "sources", ["id"], unique=False)
    op.drop_index(op.f("ix_scraping_sources_name"), table_name="scraping_sources")
    op.drop_index(op.f("ix_scraping_sources_id"), table_name="scraping_sources")
    op.drop_table("scraping_sources")
    op.drop_index(op.f("ix_event_sources_url"), table_name="event_sources")
    op.drop_index(op.f("ix_event_sources_id"), table_name="event_sources")
    op.drop_table("event_sources")
    # ### end Alembic commands ###
